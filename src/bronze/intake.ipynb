{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ad4bc75-aecc-4856-9db1-55988dc7af8f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "setup_variable"
    }
   },
   "outputs": [],
   "source": [
    "catalog = \"bronze\"\n",
    "schema = \"mastercard_reporting\"\n",
    "table_name = dbutils.widgets.get(\"table_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8eac2ac7-a086-48c5-8756-0a02e4961429",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "load_table"
    }
   },
   "outputs": [],
   "source": [
    "df_full = (spark.read.\n",
    "            format(\"csv\").\n",
    "            load(f\"/Volumes/raw/{schema}/{table_name}\", \n",
    "                 header=True, \n",
    "                 inferSchema=True\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbe41645-3929-4596-a22e-0dd998c5aae6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "verify_table_exists"
    }
   },
   "outputs": [],
   "source": [
    "def table_exists(catalog, schema, table):\n",
    "    count = (spark.sql(f\"SHOW TABLES FROM {catalog}.{schema}\")\n",
    "                .filter(f\"database = '{schema}' AND tableName = '{table}'\")\n",
    "                .count()\n",
    "            )\n",
    "    return count > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4385d3a8-884c-468f-b23a-c7dcf0d007ec",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "save_table_bronze"
    }
   },
   "outputs": [],
   "source": [
    "import delta\n",
    "\n",
    "# Condition merge tables\n",
    "def condition_table(table_name):\n",
    "    if table_name == \"cards\":\n",
    "        return \"t1.card_number = t2.card_number\"\n",
    "    elif table_name == \"cards_status\":\n",
    "        return \"t1.card_number = t2.card_number and t1.card_status = t2.card_status\"\n",
    "    elif table_name == \"cards_transactions\":\n",
    "        return \"t1.transaction_id = t2.transaction_id\"\n",
    "\n",
    "if not table_exists(catalog, schema, table_name):\n",
    "    \n",
    "    print(\"Table is creating now...\")\n",
    "    (df_full\n",
    "        .coalesce(1).\n",
    "        write.\n",
    "        format(\"delta\").\n",
    "        mode(\"overwrite\").\n",
    "        saveAsTable(f\"{catalog}.{schema}.{table_name}\")\n",
    "    )\n",
    "else:\n",
    "    print(\"Table is inserting new ids...\")\n",
    "    deltaTable = delta.DeltaTable.forName(spark, tableOrViewName=f\"{catalog}.{schema}.{table_name}\")\n",
    "    deltaTable.alias(\"t1\").merge(\n",
    "        df_full.alias(\"t2\"),\n",
    "        f\"{condition_table(table_name)}\"\n",
    "    ).whenNotMatchedInsertAll().execute()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "intake",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
