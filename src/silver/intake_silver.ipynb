{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ad4bc75-aecc-4856-9db1-55988dc7af8f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Set up variables"
    }
   },
   "outputs": [],
   "source": [
    "catalog = \"silver\"\n",
    "schema = \"mastercard_reporting\"\n",
    "table_name = 'cards_transactions'#dbutils.widgets.get(\"table_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cbe41645-3929-4596-a22e-0dd998c5aae6",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Verifying if exists tables"
    }
   },
   "outputs": [],
   "source": [
    "def table_exists(catalog, schema, table):\n",
    "    count = (spark.sql(f\"SHOW TABLES FROM {catalog}.{schema}\")\n",
    "                .filter(f\"database = '{schema}' AND tableName = '{table}'\")\n",
    "                .count()\n",
    "            )\n",
    "    return count > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ea40c74-8e9f-4932-883a-233f43707171",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Importing query"
    }
   },
   "outputs": [],
   "source": [
    "def import_query(path):\n",
    "        with open(path, \"r\") as openFile:\n",
    "            return openFile.read()\n",
    "        \n",
    "query = import_query(f\"{table_name}.sql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4385d3a8-884c-468f-b23a-c7dcf0d007ec",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Save table to silver catalog"
    }
   },
   "outputs": [],
   "source": [
    "import delta\n",
    "\n",
    "# Condition merge tables\n",
    "def condition_table(table_name):\n",
    "    if table_name == \"cards\":\n",
    "        return \"t1.card_number = t2.card_number\"\n",
    "    elif table_name == \"cards_status\":\n",
    "        return \"t1.card_status_id = t2.card_status_id\"\n",
    "    elif table_name == \"cards_transactions\":\n",
    "        return \"t1.transaction_id = t2.transaction_id\"\n",
    "\n",
    "if not table_exists(catalog, schema, table_name):\n",
    "    \n",
    "    print(\"Table is creating now...\")\n",
    "\n",
    "    (spark.sql(query)\n",
    "        .write\n",
    "        .format(\"delta\")\n",
    "        .mode(\"overwrite\")\n",
    "        .option(\"overwriteSchema\", \"true\")\n",
    "        .saveAsTable(f\"{catalog}.{schema}.{table_name}\")\n",
    "    )\n",
    "else:\n",
    "    print(\"Table is inserting new ids...\")\n",
    "    deltaTable = delta.DeltaTable.forName(spark, tableOrViewName=f\"{catalog}.{schema}.{table_name}\")\n",
    "    deltaTable.alias(\"t1\").merge(\n",
    "        spark.sql(query).alias(\"t2\"),\n",
    "        f\"{condition_table(table_name)}\"\n",
    "    ).whenNotMatchedInsertAll().execute()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "intake_silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
